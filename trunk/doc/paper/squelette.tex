%
% Fichier exemple pour MajecSTIC 2009
% -----------------------------------
% Par le comité de pilotage MajecSTIC
% majecstic-pilotage@irisa.fr
% 
% Vous pouvez éditer ce fichier pour composer votre article. Respectez la 
% langue française, pour vous aider ce document comporte des consignes 
% typographiques ainsi que des conseils pour la composition des figures et 
% des algorithmes.
%
%
%
%%%%%% NE PAS MODIFIER
%
% gillemets a la francaise
\def\leftnote#1{\leavevmode\vadjust{\setbox1=\vtop{\hsize 20mm
  \parindent=0pt\small\baselineskip=9pt
  \rightskip=4mm plus 4mm#1}
  \hbox{\kern-2cm\smash{\box1}}}}
% encore quelques petits symboles particuliers
  \font\myl=manfnt
  \def\panneau{{\myl\char"7F}}
  \def\boxone{{\myl\char"1C}}
  \def\boxtwo{{\myl\char"1D}}
  \def\ortf{{\myl\char"1E}}
  \def\fleurone{{\myl\char"26}}
  \def\fleurtwo{{\myl\char"27}}
  \def\diams{{\myl\char"23}}
  \def\cible{{\myl\char"24}}
  \def\carre{{\myl\char"25}}
  \def\fleche{{\myl\char"79}}
  \def\panneaubis{{\myl\char"7E}}
\def\panneauinverse{{\myl\char"00}}

% Conserver ces commandes (Debut)
\documentclass[twoside,a4paper,10pt]{article}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage[frenchb]{babel}
\usepackage{majecstic2009,euler,palatino}
\usepackage[french,ruled,vlined,linesnumbered]{algorithm2e}
\dontprintsemicolon
\Setnlskip{0.5em}
\incmargin{1.2em}
\usepackage{epsfig,shadow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{cite}
\usepackage{vmargin}
\pagestyle{myheadings}
\setpapersize{A4}
% Conserver ces commandes (Fin)

%===========================================================
%                               Title
%===========================================================
\newcommand{\filet}{\noindent\rule[0mm]{\textwidth}{0.2mm}}

\toappear{1} % Conserver cette ligne pour la version finale

\begin{document}

\parindent=0pt

% À FAIRE modifier en ajoutant votre titre.
% Le titre courant peut-être trop long, dans ce cas indiquez un titre 
% plus court dans la commande shorttitle (sinon, indiquez le même)
\title{\Large\bf Interrogations de moteurs de recherche par des requêtes formulées en langage naturel}

% À FAIRE modifier en ajoutant dans le premier champ vos noms et dans votre
% titre. Attention, il faut que ca tienne sur une largeur de page, donc il 
% peut etre necessaire de donner un titre plus court, ou de ne mettre que les
% noms de famille des auteurs
% Exemples:
% \markboth{Josiane Balasko, Muriel Robin \& Yves Montand}{Nos années palace.}
% \markboth
% {Dupont, Dupond, Haddock, Milou, Tintin \& Tournesol}
% {De l'exploration des profondeurs à la conquète spatiale}
\markboth
{Ludovic Bonnefoy, Romain Deveaud \& Eric Charton}
{Interrogations de moteurs de recherche par des requêtes formulées en langage naturel}

% À FAIRE Indiquez vos noms ici. Nom1, Nom2 et Nom3. Utilisez $^i$ pour 
% l'adresse i.
\author{Ludovic Bonnefoy, Romain Deveaud et Eric Charton$^1$}

% À FAIRE Indiquez vos adresses ici. Attention, la première adresse commence
% juste après le { de la commande.
\address{1: LIA / Université d'Avignon, 339 chemin des Meinajaries, 84911 Avignon\\
Contact: \texttt{ludovic.bonnefoy@etd.univ-avignon.fr}, \texttt{romain.deveaud@etd.univ-avignon.fr}, \texttt{eric.charton@univ-avignon.fr}
}

\maketitle

%===========================================================         %
%R\'esum\'e
%===========================================================  

\Resume{L'utilisation de requêtes écrites en langage naturel est un des enjeux important du secteur de la recherche d'information pour les prochaines années. Malgré le fait que ce domaine commence à être couvert par quelques grands noms de l'informatique, les réalisations disponibles à ce jour ne peuvent être considérées que comme des prototypes compte tenu des résultats actuellement visibles. Ceci peut-être expliqué par la grande diversité du langage naturel et par les nombreux sens qui peuvent être donnés à un même mot ou une même expression. Les différents critères sémantiques naturellement présents dans les phrases permettent notamment de combiner la recherche d'information classique - extrayant des documents comparés à des termes, ou mots-clés - avec des \og{}entités\fg{} ou des \og{}concepts\fg{} pouvant être apparentés à des catégories sémantiques (par exemple : \og{}personne\fg{},\og{}organisation\fg{},\og{}date\fg{}...). Nous proposerons dans cet article un système de catégorisation et d'extraction de mots-clés à partir de phrases formulées en langage naturel.}
% Une catégorisation plus fine peut également être réalisée, permettant ainsi d'obtenir une meilleure granularité des résultats ; une base de données catégorisée doit néanmoins être disponible pour pouvoir appliquer ce type de recherche d'information.}

\Abstract{Nowadays, requesting a search engine with natural language requests is a significant issue in the information retrieval research field, and some of its biggest actors begin to take it seriously. Some prototypes are actually available, but the error rate, inferred by the huge diversity of natural language and the different semantics of words or expressions, is still too large. Sentences naturally contain semantic criteria such as "entities", "concepts" or "categories" which can be combined with standard information retrieval in order to filter the documents with these semantic categories (e.g. "person", "organisation", "date"...). In this article we propose a categorization and keywords extraction system for natural language sentences.}

\MotsCles{Sémantique, catégorisation, langage naturel, recherche d'information.}
  % 5 mots cl\'es seulement!!!
\Keywords{Information retrieval, semantic, categorization, natural language.}
%=========================================================
\section{Introduction}
%=========================================================

\par De nos jours, les moteurs de recherche sont un outil pleinement utilisable par les personnes averties et habituées, malgré la volonté d'en améliorer l'accessibilité. En effet, le processus consistant à passer d'une interrogation à un enchainement de mots-clés pertinents retranscrivant correctement la pensée initiale n'est pas un exercice aisé, du moins pour les personnes qui ne sont pas familières avec l'informatique ou internet, parmi lesquelles nous pouvons par exemple compter les enfants ou certaines personnes âgées.
\par Il serait en effet idéal de pouvoir simplement formuler une question à un moteur de recherche et que celui-ci puisse donner la réponse ou du moins un ensemble de documents dans lesquels une ou des réponses se trouveraient. Des sociétés telles que Google\footnote{http://www.google.com}, Powerset\footnote{http://www.powerset.com} (propriété de Microsoft) ou Hakia\footnote{http://www.hakia.com} sont actuellement fortement investies dans le développement de solution sémantiques à l'interrogation des moteurs de recherche et l'enrichissement communautaire en est un élément central, au moins pour les deux premiers protagonistes. Ils ont en effet recours à de nombreux sites dont les informations sont éditées par des internautes contributeurs, Wikipédia\footnote{http://www.wikipedia.org} étant le plus célèbre d'entre eux.
\par C'est également notre cas, puisque le système que nous proposons s'interface NLGbAse\footnote{http://www.nlgbase.org}, une base de données classifiées provenant de Wikipédia qui peut être interrogée par le biais de trois moteurs de recherche différents. Le premier d'entre eux met en ½uvre un algorithme calculant la \emph{similarité cosinus} entre l'ensemble des mots-clés entrés et les documents issus de Wikipédia ; le deuxième est semblable au premier en tous points, à l'exception que l'on peut affiner la recherche en précisant une catégorie, ainsi seuls les documents classifiés comme appartenant à la catégorie spécifiée seront relevés. Le troisième applique quant à lui un algorithme de compacité\footnote{Référence nécessaire} permettant de trouver une entité précise étant d'une catégorie donnée, proche d'un ou plusieurs mots donnés, dans le document Wikipédia se rapportant à une entité nommée donnée, ce qui permet notamment de pouvoir proposer une réponse factuelle à une requête.
\par Ces outils constituent le système de recherche d'information sur lequel nous appliquons les sorties de notre propre système ; ce dernier peut, à partir d'une phrase en langage naturel - de préférence une question, donner les différents mots-clés et catégories attendus par les moteurs de recherche de NLGbAse, et ainsi obtenir une liste de résultats - et éventuellement des réponses factuelles - pertinents suite à une interrogation en langage naturel.
%Voulez-vous \og{}\emph{vraiment}\fg{} citer~\cite{bogdanoff:these,sonia:point} ?

\section{Analyse morpho-syntaxique et couplage des mots}
\par Pour travailler sur la sémantique, il est indispensable de posséder des outils permettant à la machine de décomposer et d'analyser la structure des phrases. C'est pourquoi nous avons utilisé un analyseur morpho-syntaxique réalisant des couplages de mots selon leur position grammaticale dans la phrase et les liant selon leurs interdépendances~\cite{linkgrammar:paper}.
% A faire
%Ici une explication du travail effectué par le parser et notre méthode pour trouver les noms propres, l'objet etc... dans une phrase.

%=============================================================
\section{Catégorisation des phrases}
%=============================================================
%=============================================================
\subsection{Catégorisation à base de règles simples}
%=============================================================

\par Notre approche pour catégoriser les questions fonctionne avec un ensemble de règles. Cet ensemble est relativement restreint car nous avons pu remarquer qu'une dizaine de règles environ pouvaientt couvrir une majorité des cas, et qu'ensuite chaque petit gain se traduisait par la production d'un nombre croissant exponentiellement de nouvelles règles. Les règles que nous avons formulées se basent principalement sur les pronoms interrogatifs des questions. En voici la liste : 
\begin{itemize}
\item Who, Whom, Whose : \emph{pers} (Person).
\item Where, Whence, Wither : si il s'agit trouver une catégorie pour le deuxième moteur de NLGbAse, et si un nom propre ou un objet est trouvé à la question alors la catégorie sera celle du \emph{nom propre} ou de l'\emph{objet} grammatical de la phrase (par exemple : \og{}Où a étudié Patrick Sébastien?\fg{}, il y a peu de chance de trouver dans la fiche de ce lieu une mention de cette personnalité et il est à priori plus judicieux de proposer la fiche de \emph{Patrick Sébastien}, dans laquelle l'utilisateur sera à même de touver l'information). Dans le cas contraire (ou si nous voulons une catégorie pour le troisième moteur), la catégorie \emph{loc} (Location) est attribuée.
\item How : nous appliquons la même procédure que précédemment, à l'exception près que si les premières conditions ne sont pas remplies, la catégorie \emph{unk} (Unknown) est attribuée. Pour ce pronom là nous avons ajouté quelques précisions lorsque nous cherchons une catégorie pour le troisème moteur : si le mot suivant directement \emph{how} fait partie de la liste suivante (far, few, great, little, many, much, tall, wide, high, big, old), la catégorie \emph{amount} est attribuée.
\item What, Why, Which : le principe est toujours le même, avec \emph{unk} (Unknown) pour valeur par défaut. Nous avons également établi, comme précédemment, une liste de mots pouvant être acceptés comme suivant directement le pronom interrogatif (comme par exemple day : \og{}What day is the Independance Day?\fg{}) et qui vont impliquer automatiquement l'attribution d'une catégorie (\emph{date} dans l'exemple précédent).
\end{itemize}
Nous allons maintenant détailler les méthodes de catégorisation des noms propres et des noms communs que nous avons mises en place.


%=============================================================
\subsection{Catégorisation par les noms propres utilisant NLGbAse}
%=============================================================
\par Comme nous l'avons vu la majorité des règles ne nous permettent pas de trancher directement, nous devons donc compléter notre analyse par un autre moyen et cela passe notamment par la catégorisation des noms propres. Nous avons remarqué que dans la majorité des cas, si un nom propre est présent dans une quest, il en est l'objet ou du moins l'objet est l'une de ses caractéristiques. Prennons par exemple ces deux questions \og{}What is the date of birth of Bruce Dickinson?\fg{}, \og{}Who is Batman's team-mate?\fg{} ; nous voyons bien que les informations désirées sont \emph{forcément} en relation avec nos noms propres.
\par Nous avons donc prit le parti de prendre comme catégorie la catégorie du nom propre se trouvant dans la question - s'il y en a un. Pour cela nous adressons une requête à un script issu de NLGbAse, qui comme nous l'avons vu associe une catégorie à chaque entité de Wikipédia, qui récupère la catégorie de l'entité correspondant à ce nom propre. Si une entité porte exactement le même nom alors la catégorie sera celle de cette entité ; si ce n'est pas le cas mais que des entités ont un nom similaire, alors la catégorie sera celle de la plus pertinente d'entres elles. Enfin si ce n'est pas le cas nous effectuons une recherche par \emph{TF.Idf}
%La solution la plus évidente aurait été de prendre pour catégorie celle du document ayant le meilleur score.
%Nous avons essayé une autre approche. 
en prenant la catégorie qui a le plus fort score, pour cela chaque catégorie se voit attribué comme score la somme des scores des documents ayant cette catégorie. De ce fait la catégorie qui rassemble le plus de pertinence sera sélectionnée.
\par Cependant nous sommes conscients qu'il arrive parfois que cette stratégie ne soit pas idéale, comme pour : \og{}What is the name of Batman's car?\fg{}. Il y a des chances que cette méthode donne \emph{pers} (Person) comme catégorie attendue alors que la solution idéale aurait probablement été \emph{prod} (Product). Cependant elle n'est pas totalement inapproprié car nous devrions trouver l'information désirée dans la fiche Wikipédia de Batman, néanmoins l'accès à la réponse est moins direct.

%=============================================================
\subsection{Catégorisation par les noms communs utilisant WordNet}
%=============================================================

\par Cependant toutes les questions ne comportent évidemment pas de noms propres mais généralement des noms communs, c'est pourquoi nous avons du trouver un moyen de traiter ces questions par une approche assez simple. La décomposition morpho-syntaxique nous permet généralement de trouver l'objet de la question, étant donné qu'il est généralement fortement porteur de sens dans une phrase, c'est celui-ci que nous allons étudier. En effet, pour la question \og{}What are the generals?\fg{}, l'objet de la question est \og{}generals\fg{} ; l'enjeu est d'arriver à associer \og{}generals\fg{} à l'étiquette \emph{fonc.mil} (fonction militaire).
\par Pour arriver à cela nous utilisons WordNet et ses hyperonymes ainsi que sa capacité à fournir une classe pour chaque mot : en effet WordNet associe déjà à la totalité des termes une étiquette, par exemple à \og{}general\fg{} WordNet associe \emph{noun.person}. L'étiquette que fournit WordNet est bien souvent satisfaisante, cependant son jeu d'étiquette ne correspond pas aux exigences d'Ester auquel notre projet doit se plier.
\par La première étape pour arranger ça fut d'associer \og{}à la main\fg{} des étiquettes à des mots qui prendront le dessus sur celles de WordNet ; pour reprendre notre exemple, nous ne voulons pas l'étiquette \emph{pers} (Person) pour \og{}general\fg{} mais bien \emph{fonc.mil}. Cependant faire ce travail sur tous les mots demanderait un investissement titanesque, et nous avons pu palier à ce problème en réfléchissant aux mots les plus généraux possibles pour chaque catégorie dont nous avions besoin. Ensuite nous vérifions que les hyponymes de ces mots sur WordNet correspondent bien à la même catégorie, et si ce n'était pas le cas nous sélectionnions tous les hyponymes pour lesquels c'est le cas et répétions cette opération. Nous sommes donc arrivés à une liste de mots caractérisant parfaitement chaque catégorie - et étant compatibles avec WordNet.
\par L'algorithme de catégorisation en lui-même consiste en une fonction récursive qui va vérifier si le nom commun ne fait pas partie des mots étiquetés. Si ce n'est pas le cas cette vérification est faite pour son hyperonyme, et ainsi de suite. La récursivité s'arrête si un mot associé à une étiquette est trouvé ou si on arrive sur l'hyperonyme de plus haut niveau. Dans le premier cas le mot de départ se voit associé cette étiquette et donc la catégorie recherchée aussi, dans le deuxième cas c'est l'étiquette associée au mot de départ qui prévaut et qui est donc définie comme la catégorie recherchée.
\par Cette méthode utilisée seule ne peut bien évidemment pas couvrir tous les cas, néanmoins c'est l'association des différentes - mais surtout complémentaires - méthodes de classification qui permet d'obtenir des résultats satisfaisants.

%Au final même si il est évident que nous ne couvrons pas tout les cas en seulement trois heures il est possible de couvrir un très grand nombre de cas puisque pour chaque mot étiqueté tout ses hyponymes reçoivent cette même étiquette.

%=============================================================
\section{Extraction des mots-clés}
%=============================================================
%Comme énoncé dans la section précédente nous utilisons un parser pour arriver à repérer les termes importants pour la catégorisation et il en est de même pour l'extraction des mots clés.

\par Comme nous l'avons expliqué, les différents moteurs de recherche de NLGbAse n'attendent pas les mêmes entrées, nous allons donc détailler ici les deux types d'extraction de mots-clés - ou mots pertinents.
 \subsection{Moteurs de recherche d'information par similarité cosinus}
\par Dans un premier temps, les mots-outils de la phrase sont automatiquement supprimés à l'aide d'un anti-dictionnaire. Nous utilisons ensuite l'analyse morpho-syntaxique de la phrase, et notamment l'arbre constitutif, pour récupérer les mots - qui ne sont pas des mots-outils - qui font partie des groupes nominaux ; malgrès son aspect simple, voire simpliste, nous avons pu prouver empyriquement son efficacité.

\subsection{Moteur de recherche d'information par algorithme de compacité (question-réponse)}
%Pour celui ci la démarche est assez proche mais le besoin de données est différent.
\par Nous l'avons déjà précisé plus haut, ce troisième moteur accepte plusieurs entrées différentes, et notamment deux champs de mots-clés. Le premier champ est une entité nommée qui va déterminer dans quel document sera appliqué l'algorithme de compacité, tandis que le deuxième champ consiste en une liste de mots qui représentent l'information cherchée ; par exemple pour la question \og{}When was Albert Einstein born?\fg{}, le mot \og{}born\fg{} devrait être sélectionné car l'information recherchée - une date de naissance en l'occurence - se trouvera certainement très proche de ce mot.
\par Dans un premier temps nous devons donc trouver l'entité nommée ; si un nom propre est présent dans la question, c'est lui qui sera directement utilisé comme entité nommée. Dans le cas contraire, nous éxécutons une requête sur NLGbAse avec l'objet de la question afin de récupérer le nom de l'entité nommée la plus pertinente. 
\par Dans un second temps vient l'extraction des mots porteurs de sens ; il s'agit tout d'abord de supprimer tout les mots-outils, les noms propres et le verbe présents dans la phrase. Il s'agit ensuite de récupérer les synonymes des mots restant avec WordNet ; pour reprendre notre exemple précédent, nous ne savons pas si le mot \fg{}born\og{} sera effectivement employé dans le document dans lequel l'information sera cherchée, c'est pourquoi nous cherchons des dérivations afin de les rajouter à notre liste et ainsi améliorer nos chances de trouver l'information. Toujours pour notre exemple, cette recherche de synonymes pourrait nous mener au mot \fg{}birth\og{}, qui serait en effet intéressant à garder dans l'optique de la recherche d'une date de naissance.


%==============================================================
\section{Expériences et résultats}
%==============================================================
\par Nous avons procédé à un certain nombre de tests et d'expériences afin d'évaluer les performances de la catégorisation comme de l'extraction des mots-clés. Nous n'avons retenu que les catégories \emph{pers}, \emph{org}, \emph{loc}, \emph{date}, \emph{amount} et \emph{unk}, les standards d'Ester 2 n'étant pas encore complètement implémentés sur la version anglaise de NLGbAse. Nous avons récupéré un corpus de questions formulées par des utilisateurs et nous les avons étiquetées en faisant mentalement le même travail que notre système, afin de pouvoir comparer ses résultats aux notres. 

\subsection{Mesures de la catégorisation}
\par Les résultats de l'attributions de catégories aux 107 phrases du corpus étiqueté sont présentés dans le tableau 1. Nous avons calculé pour chacune d'elles la précision et le rappel, puis le F-Score\footnote{Mesure harmonique combinant la précision et le rappel} en découlant.
\par Si les résultats ne semblent pas très satisfaisants, ils peuvent malgré tout mettre en perspective le fait que des règles simples couplées à une catégorisation par recherche dans une base de données sémantique peuvent être viables. Les résultats de la catégorie \emph{org} peuvent être expliqués par le fait que nous n'avons pas pu définir de règle spécifique à cette catégorie sans impacter les résultats des autres catégories, notamment \emph{pers} et \emph{loc}.

\begin{table}[h]
    \begin{center}
        \begin{tabular}{|p{2.5cm}|l|l|l|}
            \hline
            Catégorie & (\={p}) & (\={r}) & (\={F}-s) \\
            \hline
            Pers & 0.74 & 0.86 & \textbf{0.80} \\
            \hline
            Org & 0.17 & 0.07 & \textbf{0.10} \\
            \hline
            Loc & 0.60 & 0.53 & \textbf{0.56} \\
            \hline
            Date & 0.89 & 0.89 & \textbf{0.89} \\
            \hline
            Amount & 1 & 0.58 & \textbf{0.73} \\
            \hline
            Unk & 0.48 & 0.59 & \textbf{0.53} \\
            \hline
            \hline
            Total & & & \textbf{0.60} \\
            \hline
        \end{tabular}
        \caption{\label{tab:results}Précision (\={p}), Rappel (\={r}), F-Score (\={F}-s) obtenus sur le corpus de test}
    \end{center}
\end{table}

\subsection{Mesures de l'extraction de mots-clés}
% A faire

%==============================================================
\section{Conclusion}
%==============================================================
\bibliographystyle{majecstic}
\bibliography{references}

% À FAIRE: remerciements (ou supprimez les deux lignes suivantes)
%{\filet \small\\
%{\em Vous pouvez placer ici des remerciements}\\ \filet } 


\end{document}
% fin

